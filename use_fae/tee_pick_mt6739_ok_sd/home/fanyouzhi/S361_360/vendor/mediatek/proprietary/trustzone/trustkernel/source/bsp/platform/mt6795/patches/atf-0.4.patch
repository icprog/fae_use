diff --git a/Makefile b/Makefile
index c460a33..6c62443 100755
--- a/Makefile
+++ b/Makefile
@@ -59,12 +59,16 @@ else
 ifeq (${SECURE_OS},trusty)
 SPD			:= trusty
 else
+ifeq (${SECURE_OS},tkcored)
+SPD			:= opteed
+else
 #SPD			:= none
 SPD			:= fiqd
 endif
 endif
 endif
 endif
+endif
 # OEM choice
 OEMS			:= oems
 # Base commit to perform code check on
diff --git a/bl31/aarch64/runtime_exceptions.S b/bl31/aarch64/runtime_exceptions.S
index 73b4012..b442f04 100755
--- a/bl31/aarch64/runtime_exceptions.S
+++ b/bl31/aarch64/runtime_exceptions.S
@@ -373,6 +373,7 @@ smc_handler64:
 	ldr	w4, =0x82000000
 	orr	w0, w4, w5	/* x0 + 0x8200000 */
 1:
+	ldp	x4, x5, [sp, #CTX_GPREGS_OFFSET + CTX_GPREG_X4]
 #endif
 
 	/* Get the unique owning entity number */
diff --git a/include/bl32/payloads/optee.h b/include/bl32/payloads/optee.h
new file mode 100644
index 0000000..7a0286e
--- /dev/null
+++ b/include/bl32/payloads/optee.h
@@ -0,0 +1,207 @@
+/*
+ * Copyright (c) 2013-2014, ARM Limited and Contributors. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * Redistributions of source code must retain the above copyright notice, this
+ * list of conditions and the following disclaimer.
+ *
+ * Redistributions in binary form must reproduce the above copyright notice,
+ * this list of conditions and the following disclaimer in the documentation
+ * and/or other materials provided with the distribution.
+ *
+ * Neither the name of ARM nor the names of its contributors may be used
+ * to endorse or promote products derived from this software without specific
+ * prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef __OPTEE_H__
+#define __OPTEE_H__
+
+/*
+ * SMC function IDs that OPTEE uses to signal various forms of completions
+ * to the secure payload dispatcher.
+ */
+#define OPTEE_ENTRY_DONE	0xf2000000
+#define OPTEE_ON_DONE		0xf2000001
+#define OPTEE_OFF_DONE		0xf2000002
+#define OPTEE_SUSPEND_DONE	0xf2000003
+#define OPTEE_RESUME_DONE	0xf2000004
+#define OPTEE_PREEMPTED		0xf2000005
+
+/*
+ * Function identifiers to handle FIQs through the synchronous handling model.
+ * If the OPTEE was previously interrupted then control has to be returned to
+ * the OPTEED after handling the interrupt else execution can remain in the OPTEE.
+ */
+#define OPTEE_HANDLED_S_EL1_FIQ	0xf2000006
+#define OPTEE_EL3_FIQ		0xf2000007
+
+/* SMC function ID that OPTEE uses to request service from secure monitor */
+#define OPTEE_GET_ARGS		0xf2001000
+
+/*
+ * Identifiers for various OPTEE services. Corresponding function IDs (whether
+ * fast or standard) are generated by macros defined below
+ */
+#define OPTEE_ADD		0x2000
+#define OPTEE_SUB		0x2001
+#define OPTEE_MUL		0x2002
+#define OPTEE_DIV		0x2003
+#define OPTEE_HANDLE_FIQ_AND_RETURN	0x2004
+
+/*
+ * Generate function IDs for OPTEE services to be used in SMC calls, by
+ * appropriately setting bit 31 to differentiate standard and fast SMC calls
+ */
+#define OPTEE_STD_FID(fid)	((fid) | 0x72000000 | (0 << 31))
+#define OPTEE_FAST_FID(fid)	((fid) | 0x72000000 | (1 << 31))
+
+/* SMC function ID to request a previously preempted std smc */
+#define OPTEE_FID_RESUME	OPTEE_STD_FID(0x3000)
+
+/*
+ * Identify a OPTEE service from function ID filtering the last 16 bits from the
+ * SMC function ID
+ */
+#define OPTEE_BARE_FID(fid)	((fid) & 0xffff)
+
+/*
+ * Total number of function IDs implemented for services offered to NS clients.
+ * The function IDs are defined above
+ */
+#define OPTEE_NUM_FID		0x4
+
+/* OPTEE implementation version numbers */
+#define OPTEE_VERSION_MAJOR	0x0 /* Major version */
+#define OPTEE_VERSION_MINOR	0x1 /* Minor version */
+
+/*
+ * Standard Trusted OS Function IDs that fall under Trusted OS call range
+ * according to SMC calling convention
+ */
+#define TOS_CALL_COUNT		0xbf00ff00 /* Number of calls implemented */
+#define TOS_UID			0xbf00ff01 /* Implementation UID */
+/*				0xbf00ff02 is reserved */
+#define TOS_CALL_VERSION	0xbf00ff03 /* Trusted OS Call Version */
+
+/* Definitions to help the assembler access the SMC/ERET args structure */
+#define OPTEE_ARGS_SIZE		0x40
+#define OPTEE_ARG0		0x0
+#define OPTEE_ARG1		0x8
+#define OPTEE_ARG2		0x10
+#define OPTEE_ARG3		0x18
+#define OPTEE_ARG4		0x20
+#define OPTEE_ARG5		0x28
+#define OPTEE_ARG6		0x30
+#define OPTEE_ARG7		0x38
+#define OPTEE_ARGS_END		0x40
+
+#ifndef __ASSEMBLY__
+
+#include <cassert.h>
+#include <platform_def.h> /* For CACHE_WRITEBACK_GRANULE */
+#include <spinlock.h>
+#include <stdint.h>
+
+typedef uint32_t optee_vector_isn_t;
+
+typedef struct optee_vectors {
+	optee_vector_isn_t std_smc_entry;
+	optee_vector_isn_t fast_smc_entry;
+	optee_vector_isn_t cpu_on_entry;
+	optee_vector_isn_t cpu_off_entry;
+	optee_vector_isn_t cpu_resume_entry;
+	optee_vector_isn_t cpu_suspend_entry;
+	optee_vector_isn_t fiq_entry;
+} optee_vectors_t;
+
+typedef struct work_statistics {
+	uint32_t fiq_count;		/* Number of FIQs on this cpu */
+	uint32_t irq_count;		/* Number of IRQs on this cpu */
+	uint32_t sync_fiq_count;	/* Number of sync. fiqs on this cpu */
+	uint32_t sync_fiq_ret_count;	/* Number of fiq returns on this cpu */
+	uint32_t smc_count;		/* Number of returns on this cpu */
+	uint32_t eret_count;		/* Number of entries on this cpu */
+	uint32_t cpu_on_count;		/* Number of cpu on requests */
+	uint32_t cpu_off_count;		/* Number of cpu off requests */
+	uint32_t cpu_suspend_count;	/* Number of cpu suspend requests */
+	uint32_t cpu_resume_count;	/* Number of cpu resume requests */
+} __aligned(CACHE_WRITEBACK_GRANULE) work_statistics_t;
+
+typedef struct optee_args {
+	uint64_t _regs[OPTEE_ARGS_END >> 3];
+} __aligned(CACHE_WRITEBACK_GRANULE) optee_args_t;
+
+/* Macros to access members of the above structure using their offsets */
+#define read_sp_arg(args, offset)	((args)->_regs[offset >> 3])
+#define write_sp_arg(args, offset, val) (((args)->_regs[offset >> 3])	\
+					 = val)
+
+/*
+ * Ensure that the assembler's view of the size of the optee_args is the
+ * same as the compilers
+ */
+CASSERT(OPTEE_ARGS_SIZE == sizeof(optee_args_t), assert_sp_args_size_mismatch);
+
+void optee_get_magic(uint64_t args[4]);
+
+optee_args_t *optee_cpu_resume_main(uint64_t arg0,
+				uint64_t arg1,
+				uint64_t arg2,
+				uint64_t arg3,
+				uint64_t arg4,
+				uint64_t arg5,
+				uint64_t arg6,
+				uint64_t arg7);
+optee_args_t *optee_cpu_suspend_main(uint64_t arg0,
+				 uint64_t arg1,
+				 uint64_t arg2,
+				 uint64_t arg3,
+				 uint64_t arg4,
+				 uint64_t arg5,
+				 uint64_t arg6,
+				 uint64_t arg7);
+optee_args_t *optee_cpu_on_main(void);
+optee_args_t *optee_cpu_off_main(uint64_t arg0,
+			     uint64_t arg1,
+			     uint64_t arg2,
+			     uint64_t arg3,
+			     uint64_t arg4,
+			     uint64_t arg5,
+			     uint64_t arg6,
+			     uint64_t arg7);
+
+/* Generic Timer functions */
+void optee_generic_timer_start(void);
+void optee_generic_timer_handler(void);
+void optee_generic_timer_stop(void);
+void optee_generic_timer_save(void);
+void optee_generic_timer_restore(void);
+
+/* FIQ management functions */
+void optee_update_sync_fiq_stats(uint32_t type, uint64_t elr_el3);
+
+/* Data structure to keep track of OPTEE statistics */
+extern spinlock_t console_lock;
+extern work_statistics_t optee_stats[PLATFORM_CORE_COUNT];
+
+/* Vector table of jumps */
+extern optee_vectors_t optee_vector_table;
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* __BL2_H__ */
diff --git a/services/spd/opteed/opteed.mk b/services/spd/opteed/opteed.mk
new file mode 100644
index 0000000..43e9783
--- /dev/null
+++ b/services/spd/opteed/opteed.mk
@@ -0,0 +1,37 @@
+#
+# Copyright (c) 2013-2014, ARM Limited and Contributors. All rights reserved.
+#
+# Redistribution and use in source and binary forms, with or without
+# modification, are permitted provided that the following conditions are met:
+#
+# Redistributions of source code must retain the above copyright notice, this
+# list of conditions and the following disclaimer.
+#
+# Redistributions in binary form must reproduce the above copyright notice,
+# this list of conditions and the following disclaimer in the documentation
+# and/or other materials provided with the distribution.
+#
+# Neither the name of ARM nor the names of its contributors may be used
+# to endorse or promote products derived from this software without specific
+# prior written permission.
+#
+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+# POSSIBILITY OF SUCH DAMAGE.
+#
+
+OPTEED_DIR		:=	services/spd/opteed
+SPD_INCLUDES		:=	-Iinclude/bl32/payloads
+
+SPD_SOURCES		:=	services/spd/opteed/opteed_common.c	\
+				services/spd/opteed/opteed_helpers.S	\
+				services/spd/opteed/opteed_main.c	\
+				services/spd/opteed/opteed_pm.c
diff --git a/services/spd/opteed/opteed_common.c b/services/spd/opteed/opteed_common.c
new file mode 100644
index 0000000..357faa8
--- /dev/null
+++ b/services/spd/opteed/opteed_common.c
@@ -0,0 +1,149 @@
+/*
+ * Copyright (c) 2013-2014, ARM Limited and Contributors. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * Redistributions of source code must retain the above copyright notice, this
+ * list of conditions and the following disclaimer.
+ *
+ * Redistributions in binary form must reproduce the above copyright notice,
+ * this list of conditions and the following disclaimer in the documentation
+ * and/or other materials provided with the distribution.
+ *
+ * Neither the name of ARM nor the names of its contributors may be used
+ * to endorse or promote products derived from this software without specific
+ * prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <arch_helpers.h>
+#include <assert.h>
+#include <bl_common.h>
+#include <context_mgmt.h>
+#include <string.h>
+#include "opteed_private.h"
+
+/*******************************************************************************
+ * Given an OPTEE entrypoint, register width, cpu id & pointer to a
+ * context data structure, this function will create a secure context ready for
+ * programming an entry into OPTEE.
+ ******************************************************************************/
+int32_t opteed_init_secure_context(uint64_t entrypoint,
+				 uint32_t rw,
+				 uint64_t mpidr,
+				 optee_context_t *optee_ctx)
+{
+	uint32_t scr, sctlr;
+	el1_sys_regs_t *el1_state;
+	uint32_t spsr;
+
+	/* Passing a NULL context is a critical programming error */
+	assert(optee_ctx);
+
+	/*
+	 * This might look redundant if the context was statically
+	 * allocated but this function cannot make that assumption.
+	 */
+	memset(optee_ctx, 0, sizeof(*optee_ctx));
+
+	/*
+	 * Set the right security state, register width and enable access to
+	 * the secure physical timer for OPTEE.
+	 */
+	scr = read_scr();
+	scr &= ~SCR_NS_BIT;
+	scr &= ~SCR_RW_BIT;
+	scr |= SCR_ST_BIT;
+	if (rw == OPTEE_AARCH64)
+		scr |= SCR_RW_BIT;
+
+	/* Get a pointer to the S-EL1 context memory */
+	el1_state = get_sysregs_ctx(&optee_ctx->cpu_ctx);
+
+	/*
+	 * Program the SCTLR_EL1 such that upon entry in S-EL1, caches and
+	 * MMU are disabled and exception endianess is set to be the same
+	 * as EL3
+	 */
+	sctlr = read_sctlr_el3();
+	sctlr &= SCTLR_EE_BIT;
+	sctlr |= SCTLR_EL1_RES1;
+	write_ctx_reg(el1_state, CTX_SCTLR_EL1, sctlr);
+
+	/* Set this context as ready to be initialised i.e OFF */
+	set_optee_pstate(optee_ctx->state, OPTEE_PSTATE_OFF);
+
+	/* Associate this context with the cpu specified */
+	optee_ctx->mpidr = mpidr;
+
+	cm_set_context(mpidr, &optee_ctx->cpu_ctx, SECURE);
+	if (rw == OPTEE_AARCH64)
+		spsr = SPSR_64(MODE_EL1, MODE_SP_ELX, DISABLE_ALL_EXCEPTIONS);
+	else
+		spsr = SPSR_MODE32(MODE32_svc, SPSR_T_ARM, SPSR_E_LITTLE,
+				   DAIF_FIQ_BIT | DAIF_IRQ_BIT);
+	cm_set_el3_eret_context(SECURE, entrypoint, spsr, scr);
+
+	return 0;
+}
+
+/*******************************************************************************
+ * This function takes an OPTEE context pointer and:
+ * 1. Applies the S-EL1 system register context from optee_ctx->cpu_ctx.
+ * 2. Saves the current C runtime state (callee saved registers) on the stack
+ *    frame and saves a reference to this state.
+ * 3. Calls el3_exit() so that the EL3 system and general purpose registers
+ *    from the optee_ctx->cpu_ctx are used to enter the OPTEE image.
+ ******************************************************************************/
+uint64_t opteed_synchronous_sp_entry(optee_context_t *optee_ctx)
+{
+	uint64_t rc;
+
+	assert(optee_ctx->c_rt_ctx == 0);
+
+	/* Apply the Secure EL1 system register context and switch to it */
+	assert(cm_get_context(read_mpidr(), SECURE) == &optee_ctx->cpu_ctx);
+	cm_el1_sysregs_context_restore(SECURE);
+	cm_set_next_eret_context(SECURE);
+
+	rc = opteed_enter_sp(&optee_ctx->c_rt_ctx);
+#if DEBUG
+	optee_ctx->c_rt_ctx = 0;
+#endif
+
+	return rc;
+}
+
+
+/*******************************************************************************
+ * This function takes an OPTEE context pointer and:
+ * 1. Saves the S-EL1 system register context tp optee_ctx->cpu_ctx.
+ * 2. Restores the current C runtime state (callee saved registers) from the
+ *    stack frame using the reference to this state saved in opteed_enter_sp().
+ * 3. It does not need to save any general purpose or EL3 system register state
+ *    as the generic smc entry routine should have saved those.
+ ******************************************************************************/
+void opteed_synchronous_sp_exit(optee_context_t *optee_ctx, uint64_t ret)
+{
+	/* Save the Secure EL1 system register context */
+	assert(cm_get_context(read_mpidr(), SECURE) == &optee_ctx->cpu_ctx);
+	cm_el1_sysregs_context_save(SECURE);
+
+	assert(optee_ctx->c_rt_ctx != 0);
+	opteed_exit_sp(optee_ctx->c_rt_ctx, ret);
+
+	/* Should never reach here */
+	assert(0);
+}
diff --git a/services/spd/opteed/opteed_helpers.S b/services/spd/opteed/opteed_helpers.S
new file mode 100644
index 0000000..58aebd4
--- /dev/null
+++ b/services/spd/opteed/opteed_helpers.S
@@ -0,0 +1,120 @@
+/*
+ * Copyright (c) 2013-2014, ARM Limited and Contributors. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * Redistributions of source code must retain the above copyright notice, this
+ * list of conditions and the following disclaimer.
+ *
+ * Redistributions in binary form must reproduce the above copyright notice,
+ * this list of conditions and the following disclaimer in the documentation
+ * and/or other materials provided with the distribution.
+ *
+ * Neither the name of ARM nor the names of its contributors may be used
+ * to endorse or promote products derived from this software without specific
+ * prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <asm_macros.S>
+#include "opteed_private.h"
+
+	.global	opteed_enter_sp
+	/* ---------------------------------------------
+	 * This function is called with SP_EL0 as stack.
+	 * Here we stash our EL3 callee-saved registers
+	 * on to the stack as a part of saving the C
+	 * runtime and enter the secure payload.
+	 * 'x0' contains a pointer to the memory where
+	 * the address of the C runtime context is to be
+	 * saved.
+	 * ---------------------------------------------
+	 */
+func opteed_enter_sp
+	/* Make space for the registers that we're going to save */
+	mov	x3, sp
+	str	x3, [x0, #0]
+	sub	sp, sp, #OPTEED_C_RT_CTX_SIZE
+
+	/* Save callee-saved registers on to the stack */
+	stp	x19, x20, [sp, #OPTEED_C_RT_CTX_X19]
+	stp	x21, x22, [sp, #OPTEED_C_RT_CTX_X21]
+	stp	x23, x24, [sp, #OPTEED_C_RT_CTX_X23]
+	stp	x25, x26, [sp, #OPTEED_C_RT_CTX_X25]
+	stp	x27, x28, [sp, #OPTEED_C_RT_CTX_X27]
+	stp	x29, x30, [sp, #OPTEED_C_RT_CTX_X29]
+
+	/* ---------------------------------------------
+	 * Save scr_el3
+	 *
+	 * Without this it will caused a problem when we
+	 * have a 32bit Secure OS and 64bit rich OS.
+	 * After el3_exit, scr_el3 will be modified to
+	 * 32bit mode, the psci common code will use scr_el3
+	 * to determine which mode(32 or 64bit) it should
+	 * use to return to normal world. Thus, it will in
+	 * turn caused entering 64bit linux with 32bit mode
+	 * ---------------------------------------------
+	 */
+	mrs	x19, scr_el3
+	stp	x19, xzr, [sp, #OPTEED_C_RT_CTX_SCR]
+
+	/* ---------------------------------------------
+	 * Everything is setup now. el3_exit() will
+	 * use the secure context to restore to the
+	 * general purpose and EL3 system registers to
+	 * ERET into OPTEE.
+	 * ---------------------------------------------
+	 */
+	b	el3_exit
+
+	/* ---------------------------------------------
+	 * This function is called 'x0' pointing to a C
+	 * runtime context saved in opteed_enter_sp().  It
+	 * restores the saved registers and jumps to
+	 * that runtime with 'x0' as the new sp. This
+	 * destroys the C runtime context that had been
+	 * built on the stack below the saved context by
+	 * the caller. Later the second parameter 'x1'
+	 * is passed as return value to the caller
+	 * ---------------------------------------------
+	 */
+	.global opteed_exit_sp
+func opteed_exit_sp
+	/* Restore the previous stack */
+	mov	sp, x0
+
+	/* Restore scr_el3 */
+	ldp	x19, xzr, [sp, #(OPTEED_C_RT_CTX_SCR - OPTEED_C_RT_CTX_SIZE)]
+	msr	scr_el3, x19
+
+	/* Restore callee-saved registers on to the stack */
+	ldp	x19, x20, [x0, #(OPTEED_C_RT_CTX_X19 - OPTEED_C_RT_CTX_SIZE)]
+	ldp	x21, x22, [x0, #(OPTEED_C_RT_CTX_X21 - OPTEED_C_RT_CTX_SIZE)]
+	ldp	x23, x24, [x0, #(OPTEED_C_RT_CTX_X23 - OPTEED_C_RT_CTX_SIZE)]
+	ldp	x25, x26, [x0, #(OPTEED_C_RT_CTX_X25 - OPTEED_C_RT_CTX_SIZE)]
+	ldp	x27, x28, [x0, #(OPTEED_C_RT_CTX_X27 - OPTEED_C_RT_CTX_SIZE)]
+	ldp	x29, x30, [x0, #(OPTEED_C_RT_CTX_X29 - OPTEED_C_RT_CTX_SIZE)]
+
+	/* ---------------------------------------------
+	 * This should take us back to the instruction
+	 * after the call to the last opteed_enter_sp().
+	 * Place the second parameter to x0 so that the
+	 * caller will see it as a return value from the
+	 * original entry call
+	 * ---------------------------------------------
+	 */
+	mov	x0, x1
+	ret
diff --git a/services/spd/opteed/opteed_main.c b/services/spd/opteed/opteed_main.c
new file mode 100644
index 0000000..1e936cb
--- /dev/null
+++ b/services/spd/opteed/opteed_main.c
@@ -0,0 +1,480 @@
+/*
+ * Copyright (c) 2013-2014, ARM Limited and Contributors. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * Redistributions of source code must retain the above copyright notice, this
+ * list of conditions and the following disclaimer.
+ *
+ * Redistributions in binary form must reproduce the above copyright notice,
+ * this list of conditions and the following disclaimer in the documentation
+ * and/or other materials provided with the distribution.
+ *
+ * Neither the name of ARM nor the names of its contributors may be used
+ * to endorse or promote products derived from this software without specific
+ * prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+
+/*******************************************************************************
+ * This is the Secure Payload Dispatcher (SPD). The dispatcher is meant to be a
+ * plug-in component to the Secure Monitor, registered as a runtime service. The
+ * SPD is expected to be a functional extension of the Secure Payload (SP) that
+ * executes in Secure EL1. The Secure Monitor will delegate all SMCs targeting
+ * the Trusted OS/Applications range to the dispatcher. The SPD will either
+ * handle the request locally or delegate it to the Secure Payload. It is also
+ * responsible for initialising and maintaining communication with the SP.
+ ******************************************************************************/
+#include <arch_helpers.h>
+#include <assert.h>
+#include <bl_common.h>
+#include <bl31.h>
+#include <context_mgmt.h>
+#include <debug.h>
+#include <errno.h>
+#include <platform.h>
+#include <runtime_svc.h>
+#include <stddef.h>
+#include <optee.h>
+#include <uuid.h>
+#include "opteed_private.h"
+#include "teesmc.h"
+#include "teesmc_opteed.h"
+
+/*******************************************************************************
+ * Address of the entrypoint vector table in OPTEE. It is
+ * initialised once on the primary core after a cold boot.
+ ******************************************************************************/
+optee_vectors_t *optee_vectors;
+
+/*******************************************************************************
+ * Array to keep track of per-cpu OPTEE state
+ ******************************************************************************/
+optee_context_t opteed_sp_context[OPTEED_CORE_COUNT];
+uint32_t opteed_rw;
+
+//static uint64_t opteeBaseCoreMpidr;
+
+
+//static int32_t opteed_init(void);
+static int32_t opteed_init(unsigned int tee_entry, unsigned int boot_arg_addr);
+
+/*******************************************************************************
+ * This function is the handler registered for S-EL1 interrupts by the
+ * OPTEED. It validates the interrupt and upon success arranges entry into
+ * the OPTEE at 'optee_fiq_entry()' for handling the interrupt.
+ ******************************************************************************/
+
+static uint64_t opteed_sel1_interrupt_handler(uint32_t id,
+					    uint32_t flags,
+					    void *handle,
+					    void *cookie)
+{
+	uint32_t linear_id;
+	uint64_t mpidr;
+	optee_context_t *optee_ctx;
+
+	/* Check the security state when the exception was generated */
+	assert(get_interrupt_src_ss(flags) == NON_SECURE);
+
+#if IMF_READ_INTERRUPT_ID
+	/* Check the security status of the interrupt */
+	assert(plat_ic_get_interrupt_type(id) == INTR_TYPE_S_EL1);
+#endif
+
+	/* Sanity check the pointer to this cpu's context */
+	mpidr = read_mpidr();
+	assert(handle == cm_get_context(mpidr, NON_SECURE));
+
+	/* Save the non-secure context before entering the OPTEE */
+	cm_el1_sysregs_context_save(NON_SECURE);
+
+	/* Get a reference to this cpu's OPTEE context */
+	linear_id = platform_get_core_pos(mpidr);
+	optee_ctx = &opteed_sp_context[linear_id];
+	assert(&optee_ctx->cpu_ctx == cm_get_context(mpidr, SECURE));
+
+#if 0
+	SMC_SET_EL3(&optee_ctx->cpu_ctx,
+		    CTX_SPSR_EL3,
+		    SPSR_64(MODE_EL1, MODE_SP_ELX, DISABLE_ALL_EXCEPTIONS));
+#endif
+	SMC_SET_EL3(&optee_ctx->cpu_ctx,
+		    CTX_ELR_EL3,
+		    (uint64_t)&optee_vectors->fiq_entry);
+	cm_el1_sysregs_context_restore(SECURE);
+	cm_set_next_eret_context(SECURE);
+
+	/*
+	 * Tell the OPTEE that it has to handle an FIQ synchronously. Also the
+	 * instruction in normal world where the interrupt was generated is
+	 * passed for debugging purposes. It is safe to retrieve this address
+	 * from ELR_EL3 as the secure context will not take effect until
+	 * el3_exit().
+	 */
+	SMC_RET2(&optee_ctx->cpu_ctx, OPTEE_HANDLE_FIQ_AND_RETURN,
+		 read_elr_el3());
+}
+
+// Core-specific context initialization for non-primary cores
+void opteed_init_core(uint64_t mpidr) {
+#if 0
+	uint32_t linear_id = platform_get_core_pos(mpidr);
+	optee_context_t *optee_ctx = &opteed_sp_context[linear_id];
+	uint32_t boot_core_nro;
+  
+	tbase_init_secure_context(tbase_ctx);
+  
+	boot_core_nro = platform_get_core_pos(opteeBootCoreMpidr);
+	save_sysregs_core(boot_core_nro, linear_id);
+#endif
+}
+
+/*******************************************************************************
+ * Secure Payload Dispatcher setup. The SPD finds out the SP entrypoint and type
+ * (aarch32/aarch64) if not already known and initialises the context for entry
+ * into the SP for its initialisation.
+ ******************************************************************************/
+int32_t opteed_setup(void)
+{
+	entry_point_info_t *image_info;
+	int32_t rc;
+	uint64_t mpidr = read_mpidr();
+	uint32_t linear_id;
+
+	linear_id = platform_get_core_pos(mpidr);
+
+	/*
+	 * Get information about the Secure Payload (BL32) image. Its
+	 * absence is a critical failure.  TODO: Add support to
+	 * conditionally include the SPD service
+	 */
+	image_info = bl31_plat_get_next_image_ep_info(SECURE);
+	assert(image_info);
+
+	/*
+	 * If there's no valid entry point for SP, we return a non-zero value
+	 * signalling failure initializing the service. We bail out without
+	 * registering any handlers
+	 */
+	if (!image_info->pc)
+		return 1;
+
+	/*
+	 * We could inspect the SP image and determine it's execution
+	 * state i.e whether AArch32 or AArch64. Assuming it's AArch32
+	 * for the time being.
+	 */
+	opteed_rw = OPTEE_AARCH32;
+	rc = opteed_init_secure_context(image_info->pc, opteed_rw,
+				        mpidr, &opteed_sp_context[linear_id]);
+	assert(rc == 0);
+
+	/*
+	 * All OPTEED initialization done. Now register our init function with
+	 * BL31 for deferred invocation
+	 */
+	bl31_register_bl32_init(&opteed_init);
+
+	return rc;
+}
+
+/*******************************************************************************
+ * This function passes control to the OPTEE image (BL32) for the first time
+ * on the primary cpu after a cold boot. It assumes that a valid secure
+ * context has already been created by opteed_setup() which can be directly
+ * used.  It also assumes that a valid non-secure context has been
+ * initialised by PSCI so it does not need to save and restore any
+ * non-secure state. This function performs a synchronous entry into
+ * OPTEE. OPTEE passes control back to this routine through a SMC.
+ ******************************************************************************/
+static int32_t opteed_init(unsigned int tee_entry, unsigned int boot_arg_addr)
+{
+	uint64_t mpidr = read_mpidr();
+	uint32_t linear_id = platform_get_core_pos(mpidr), flags;
+	uint64_t rc;
+	optee_context_t *optee_ctx = &opteed_sp_context[linear_id];
+
+	// Save el1 registers in case non-secure world has already been set up.
+  	cm_el1_sysregs_context_save(NON_SECURE);
+
+	/*
+	 * Arrange for an entry into the test secure payload. We expect an array
+	 * of vectors in return
+	 */
+	printf("Init OP-TEE\n");
+	rc = opteed_synchronous_sp_entry(optee_ctx);
+	printf("Init return\n");
+	assert(rc != 0);
+	if (rc) {
+		set_optee_pstate(optee_ctx->state, OPTEE_PSTATE_ON);
+
+		/*
+		 * OPTEE has been successfully initialized. Register power
+		 * managemnt hooks with PSCI
+		 */
+		psci_register_spd_pm_hook(&opteed_pm);
+	}
+
+	/*
+	 * Register an interrupt handler for S-EL1 interrupts when generated
+	 * during code executing in the non-secure state.
+	 */
+	flags = 0;
+	set_interrupt_rm_flag(flags, NON_SECURE);
+	rc = register_interrupt_type_handler(INTR_TYPE_S_EL1,
+					     opteed_sel1_interrupt_handler,
+					     flags);
+	if (rc)
+		panic();
+
+	cm_el1_sysregs_context_restore(NON_SECURE);
+
+	return rc;
+}
+
+
+/*******************************************************************************
+ * This function is responsible for handling all SMCs in the Trusted OS/App
+ * range from the non-secure state as defined in the SMC Calling Convention
+ * Document. It is also responsible for communicating with the Secure
+ * payload to delegate work and return results back to the non-secure
+ * state. Lastly it will also return any information that OPTEE needs to do
+ * the work assigned to it.
+ ******************************************************************************/
+uint64_t opteed_smc_handler(uint32_t smc_fid,
+			 uint64_t x1,
+			 uint64_t x2,
+			 uint64_t x3,
+			 uint64_t x4,
+			 void *cookie,
+			 void *handle,
+			 uint64_t flags)
+{
+	cpu_context_t *ns_cpu_context;
+	unsigned long mpidr = read_mpidr();
+	uint32_t linear_id = platform_get_core_pos(mpidr);
+	optee_context_t *optee_ctx = &opteed_sp_context[linear_id];
+
+	printf("%s ns 0x%x\n", __func__, is_caller_non_secure(flags));
+
+
+
+	/*
+	 * Determine which security state this SMC originated from
+	 */
+
+	if (is_caller_non_secure(flags)) {
+		/*
+		 * This is a fresh request from the non-secure client.
+		 * The parameters are in x1 and x2. Figure out which
+		 * registers need to be preserved, save the non-secure
+		 * state and send the request to the secure payload.
+		 */
+		assert(handle == cm_get_context(mpidr, NON_SECURE));
+
+		cm_el1_sysregs_context_save(NON_SECURE);
+
+		/*
+		 * We are done stashing the non-secure context. Ask the
+		 * OPTEE to do the work now.
+		 */
+
+		/*
+		 * Verify if there is a valid context to use, copy the
+		 * operation type and parameters to the secure context
+		 * and jump to the fast smc entry point in the secure
+		 * payload. Entry into S-EL1 will take place upon exit
+		 * from this function.
+		 */
+		assert(&optee_ctx->cpu_ctx ==
+			cm_get_context(mpidr, SECURE));
+
+		/* Set appropriate entry for SMC.
+		 * We expect OPTEE to manage the PSTATE.I and PSTATE.F
+		 * flags as appropriate.
+		 */
+		if (GET_SMC_TYPE(smc_fid) == SMC_TYPE_FAST) {
+			cm_set_elr_el3(SECURE, (uint64_t)
+					&optee_vectors->fast_smc_entry);
+		} else {
+			cm_set_elr_el3(SECURE, (uint64_t)
+					&optee_vectors->std_smc_entry);
+		}
+
+		cm_el1_sysregs_context_restore(SECURE);
+		cm_set_next_eret_context(SECURE);
+
+		/* Propagate hypervisor client ID */
+		write_ctx_reg(get_gpregs_ctx(&optee_ctx->cpu_ctx),
+			      CTX_GPREG_X7,
+			      read_ctx_reg(get_gpregs_ctx(handle),
+					   CTX_GPREG_X7));
+
+		SMC_RET4(&optee_ctx->cpu_ctx, smc_fid, x1, x2, x3);
+	}
+
+	/*
+	 * Returning from OPTEE
+	 */
+
+	switch (smc_fid) {
+	/*
+	 * OPTEE has finished initialising itself after a cold boot
+	 */
+	case TEESMC32_OPTEED_RETURN_ENTRY_DONE:
+	case TEESMC64_OPTEED_RETURN_ENTRY_DONE:
+		/*
+		 * Stash the OPTEE entry points information. This is done
+		 * only once on the primary cpu
+		 */
+		assert(optee_vectors == NULL);
+		optee_vectors = (optee_vectors_t *) x1;
+
+		/*
+		 * OPTEE reports completion. The OPTEED must have initiated
+		 * the original request through a synchronous entry into
+		 * the SP. Jump back to the original C runtime context.
+		 */
+		 printf("RETURN_ENTRY_DONE smc_fid %x x1 0x%x x2 0x%x x3 0x%x x4 0x%x\n",
+		 	smc_fid, x1, x2, x3, x4);
+
+		opteed_synchronous_sp_exit(optee_ctx, x1);
+
+
+	/*
+	 * OPTEE has finished turning itself on in response to an earlier
+	 * psci cpu_on request
+	 */
+	case TEESMC32_OPTEED_RETURN_ON_DONE:
+	case TEESMC64_OPTEED_RETURN_ON_DONE:
+
+	/*
+	 * OPTEE has finished turning itself off in response to an earlier
+	 * psci cpu_off request.
+	 */
+	case TEESMC32_OPTEED_RETURN_OFF_DONE:
+	case TEESMC64_OPTEED_RETURN_OFF_DONE:
+	/*
+	 * OPTEE has finished resuming itself after an earlier psci
+	 * cpu_suspend request.
+	 */
+	case TEESMC32_OPTEED_RETURN_RESUME_DONE:
+	case TEESMC64_OPTEED_RETURN_RESUME_DONE:
+	/*
+	 * OPTEE has finished suspending itself after an earlier psci
+	 * cpu_suspend request.
+	 */
+	case TEESMC32_OPTEED_RETURN_SUSPEND_DONE:
+	case TEESMC64_OPTEED_RETURN_SUSPEND_DONE:
+
+		printf("RETURN_SUSPEND_DONE: smc_fid %x x1 0x%x x2 0x%x x3 0x%x x4 0x%x\n",
+			smc_fid, x1, x2, x3, x4);
+
+		/*
+		 * OPTEE reports completion. The OPTEED must have initiated the
+		 * original request through a synchronous entry into OPTEE.
+		 * Jump back to the original C runtime context, and pass x1 as
+		 * return value to the caller
+		 */
+		opteed_synchronous_sp_exit(optee_ctx, x1);
+
+	/*
+	 * OPTEE is returning from a call or being preemted from a call, in
+	 * either case execution should resume in the normal world.
+	 */
+	case TEESMC32_OPTEED_RETURN_CALL_DONE:
+	case TEESMC64_OPTEED_RETURN_CALL_DONE:
+		/*
+		 * This is the result from the secure client of an
+		 * earlier request. The results are in x0-x3. Copy it
+		 * into the non-secure context, save the secure state
+		 * and return to the non-secure state.
+		 */
+		assert(handle == cm_get_context(mpidr, SECURE));
+
+		printf("RETURN_CALL_DONE: smc_fid %x x1 0x%x x2 0x%x x3 0x%x x4 0x%x\n",
+			smc_fid, x1, x2, x3, x4);
+
+		cm_el1_sysregs_context_save(SECURE);
+
+		/* Get a reference to the non-secure context */
+		ns_cpu_context = cm_get_context(mpidr, NON_SECURE);
+		assert(ns_cpu_context);
+
+		/* Restore non-secure state */
+		cm_el1_sysregs_context_restore(NON_SECURE);
+		cm_set_next_eret_context(NON_SECURE);
+
+		x1 &= ((1UL << 32) - 1);
+		x2 &= ((1UL << 32) - 1);
+		x3 &= ((1UL << 32) - 1);
+		x4 &= ((1UL << 32) - 1);
+
+		printf("RETURN_CALL_DONE_after: smc_fid %x x1 0x%x x2 0x%x x3 0x%x x4 0x%x\n",
+			smc_fid, x1, x2, x3, x4);
+
+		SMC_RET4(ns_cpu_context, x1, x2, x3, x4);
+
+	/*
+	 * OPTEE has finished handling a S-EL1 FIQ interrupt. Execution
+	 * should resume in the normal world.
+	 */
+	case TEESMC32_OPTEED_RETURN_FIQ_DONE:
+	case TEESMC64_OPTEED_RETURN_FIQ_DONE:
+		/* Get a reference to the non-secure context */
+		ns_cpu_context = cm_get_context(mpidr, NON_SECURE);
+		assert(ns_cpu_context);
+
+		printf("RETURN_FIQ_DONE: smc_fid %x x1 0x%x x2 0x%x x3 0x%x x4 0x%x\n",
+			smc_fid, x1, x2, x2, x3, x4);
+
+		/*
+		 * Restore non-secure state. There is no need to save the
+		 * secure system register context since OPTEE was supposed
+		 * to preserve it during S-EL1 interrupt handling.
+		 */
+		cm_el1_sysregs_context_restore(NON_SECURE);
+		cm_set_next_eret_context(NON_SECURE);
+
+		SMC_RET0((uint64_t) ns_cpu_context);
+
+	default:
+		assert(0);
+	}
+}
+
+/* Define an OPTEED runtime service descriptor for fast SMC calls */
+DECLARE_RT_SVC(
+	opteed_fast,
+
+	OEN_TOS_START,
+	OEN_TOS_END,
+	SMC_TYPE_FAST,
+	opteed_setup,
+	opteed_smc_handler
+);
+
+/* Define an OPTEED runtime service descriptor for standard SMC calls */
+DECLARE_RT_SVC(
+	opteed_std,
+
+	OEN_TOS_START,
+	OEN_TOS_END,
+	SMC_TYPE_STD,
+	NULL,
+	opteed_smc_handler
+);
diff --git a/services/spd/opteed/opteed_pm.c b/services/spd/opteed/opteed_pm.c
new file mode 100644
index 0000000..8aae461
--- /dev/null
+++ b/services/spd/opteed/opteed_pm.c
@@ -0,0 +1,226 @@
+/*
+ * Copyright (c) 2013-2014, ARM Limited and Contributors. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * Redistributions of source code must retain the above copyright notice, this
+ * list of conditions and the following disclaimer.
+ *
+ * Redistributions in binary form must reproduce the above copyright notice,
+ * this list of conditions and the following disclaimer in the documentation
+ * and/or other materials provided with the distribution.
+ *
+ * Neither the name of ARM nor the names of its contributors may be used
+ * to endorse or promote products derived from this software without specific
+ * prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <arch_helpers.h>
+#include <assert.h>
+#include <bl_common.h>
+#include <context_mgmt.h>
+#include <debug.h>
+#include <platform.h>
+#include <optee.h>
+#include "opteed_private.h"
+
+/*******************************************************************************
+ * The target cpu is being turned on. Allow the OPTEED/OPTEE to perform any
+ * actions needed. Nothing at the moment.
+ ******************************************************************************/
+static void opteed_cpu_on_handler(uint64_t target_cpu)
+{
+
+	uint64_t mpidr = read_mpidr();
+	uint32_t linear_id = platform_get_core_pos(mpidr);
+
+	printf("%s target_cpu 0x%lx\n", __func__, target_cpu);
+	optee_context_t *optee_ctx = &opteed_sp_context[linear_id];
+
+  // TODO
+
+	set_optee_pstate(optee_ctx->state, OPTEE_PSTATE_ON);
+}
+
+/*******************************************************************************
+ * This cpu is being turned off. Allow the OPTEED/OPTEE to perform any actions
+ * needed
+ ******************************************************************************/
+static int32_t opteed_cpu_off_handler(uint64_t cookie)
+{
+	int32_t rc = 0;
+	uint64_t mpidr = read_mpidr();
+	uint32_t linear_id = platform_get_core_pos(mpidr);
+
+	optee_context_t *optee_ctx = &opteed_sp_context[linear_id];
+
+	printf("%s cookie 0x%lx\n", __func__, cookie);
+
+	assert(optee_vectors);
+	assert(get_optee_pstate(optee_ctx->state) == OPTEE_PSTATE_ON);
+
+	/* Program the entry point and enter OPTEE */
+	cm_set_elr_el3(SECURE, (uint64_t) &optee_vectors->cpu_off_entry);
+	rc = opteed_synchronous_sp_entry(optee_ctx);
+
+	/*
+	 * Read the response from OPTEE. A non-zero return means that
+	 * something went wrong while communicating with OPTEE.
+	 */
+	if (rc != 0)
+		panic();
+
+	/*
+	 * Reset OPTEE's context for a fresh start when this cpu is turned on
+	 * subsequently.
+	 */
+	set_optee_pstate(optee_ctx->state, OPTEE_PSTATE_OFF);
+
+	 return 0;
+}
+
+/*******************************************************************************
+ * This cpu is being suspended. S-EL1 state must have been saved in the
+ * resident cpu (mpidr format) if it is a UP/UP migratable OPTEE.
+ ******************************************************************************/
+static void opteed_cpu_suspend_handler(uint64_t power_state)
+{
+	int32_t rc = 0;
+	uint64_t mpidr = read_mpidr();
+	uint32_t linear_id = platform_get_core_pos(mpidr);
+	optee_context_t *optee_ctx = &opteed_sp_context[linear_id];
+
+	printf("%s power_state 0x%x\n", __func__, power_state);
+
+	assert(optee_vectors);
+	assert(get_optee_pstate(optee_ctx->state) == OPTEE_PSTATE_ON);
+
+	/* Program the entry point, power_state parameter and enter OPTEE */
+	write_ctx_reg(get_gpregs_ctx(&optee_ctx->cpu_ctx),
+		      CTX_GPREG_X0,
+		      power_state);
+	cm_set_elr_el3(SECURE, (uint64_t) &optee_vectors->cpu_suspend_entry);
+	rc = opteed_synchronous_sp_entry(optee_ctx);
+
+	/*
+	 * Read the response from OPTEE. A non-zero return means that
+	 * something went wrong while communicating with OPTEE.
+	 */
+	if (rc != 0)
+		panic();
+
+	/* Update its context to reflect the state OPTEE is in */
+	set_optee_pstate(optee_ctx->state, OPTEE_PSTATE_SUSPEND);
+}
+
+/*******************************************************************************
+ * This cpu has been turned on. Enter OPTEE to initialise S-EL1 and other bits
+ * before passing control back to the Secure Monitor. Entry in S-El1 is done
+ * after initialising minimal architectural state that guarantees safe
+ * execution.
+ ******************************************************************************/
+static void opteed_cpu_on_finish_handler(uint64_t cookie)
+{
+	int32_t rc = 0;
+	uint64_t mpidr = read_mpidr();
+	uint32_t linear_id = platform_get_core_pos(mpidr);
+	optee_context_t *optee_ctx = &opteed_sp_context[linear_id];
+
+	printf("%s: cookie 0x%x\n", __func__, cookie);
+
+	assert(optee_vectors);
+	assert(get_optee_pstate(optee_ctx->state) == OPTEE_PSTATE_OFF);
+	
+	//opteed_init_core(mpidr);
+
+	/* Initialise this cpu's secure context */
+	opteed_init_secure_context((uint64_t)&optee_vectors->cpu_on_entry,
+				   opteed_rw, mpidr, optee_ctx);
+
+	/* Enter OPTEE */
+	rc = opteed_synchronous_sp_entry(optee_ctx);
+
+	/*
+	 * Read the response from OPTEE. A non-zero return means that
+	 * something went wrong while communicating with OPTEE.
+	 */
+	if (rc != 0)
+		panic();
+
+	/* Update its context to reflect the state OPTEE is in */
+	set_optee_pstate(optee_ctx->state, OPTEE_PSTATE_ON);
+}
+
+/*******************************************************************************
+ * This cpu has resumed from suspend. The OPTEED saved the OPTEE context when it
+ * completed the preceding suspend call. Use that context to program an entry
+ * into OPTEE to allow it to do any remaining book keeping
+ ******************************************************************************/
+static void opteed_cpu_suspend_finish_handler(uint64_t suspend_level)
+{
+	int32_t rc = 0;
+	uint64_t mpidr = read_mpidr();
+	uint32_t linear_id = platform_get_core_pos(mpidr);
+
+	optee_context_t *optee_ctx = &opteed_sp_context[linear_id];
+
+	printf("%s: suspend_level 0x%x\n", __func__, suspend_level);
+
+	assert(optee_vectors);
+	assert(get_optee_pstate(optee_ctx->state) == OPTEE_PSTATE_SUSPEND);
+
+	/* Program the entry point, suspend_level and enter the SP */
+	write_ctx_reg(get_gpregs_ctx(&optee_ctx->cpu_ctx),
+		      CTX_GPREG_X0,
+		      suspend_level);
+	cm_set_elr_el3(SECURE, (uint64_t) &optee_vectors->cpu_resume_entry);
+	rc = opteed_synchronous_sp_entry(optee_ctx);
+
+	/*
+	 * Read the response from OPTEE. A non-zero return means that
+	 * something went wrong while communicating with OPTEE.
+	 */
+	if (rc != 0)
+		panic();
+
+	/* Update its context to reflect the state OPTEE is in */
+	set_optee_pstate(optee_ctx->state, OPTEE_PSTATE_ON);
+}
+
+/*******************************************************************************
+ * Return the type of OPTEE the OPTEED is dealing with. Report the current
+ * resident cpu (mpidr format) if it is a UP/UP migratable OPTEE.
+ ******************************************************************************/
+static int32_t opteed_cpu_migrate_info(uint64_t *resident_cpu)
+{
+	return OPTEE_MIGRATE_INFO;
+}
+
+/*******************************************************************************
+ * Structure populated by the OPTEE Dispatcher to be given a chance to
+ * perform any OPTEE bookkeeping before PSCI executes a power mgmt.
+ * operation.
+ ******************************************************************************/
+const spd_pm_ops_t opteed_pm = {
+	opteed_cpu_on_handler,
+	opteed_cpu_off_handler,
+	opteed_cpu_suspend_handler,
+	opteed_cpu_on_finish_handler,
+	opteed_cpu_suspend_finish_handler,
+	NULL,
+	opteed_cpu_migrate_info
+};
+
diff --git a/services/spd/opteed/opteed_private.h b/services/spd/opteed/opteed_private.h
new file mode 100644
index 0000000..b57d049
--- /dev/null
+++ b/services/spd/opteed/opteed_private.h
@@ -0,0 +1,167 @@
+/*
+ * Copyright (c) 2013-2014, ARM Limited and Contributors. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * Redistributions of source code must retain the above copyright notice, this
+ * list of conditions and the following disclaimer.
+ *
+ * Redistributions in binary form must reproduce the above copyright notice,
+ * this list of conditions and the following disclaimer in the documentation
+ * and/or other materials provided with the distribution.
+ *
+ * Neither the name of ARM nor the names of its contributors may be used
+ * to endorse or promote products derived from this software without specific
+ * prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef __OPTEED_PRIVATE_H__
+#define __OPTEED_PRIVATE_H__
+
+#include <arch.h>
+#include <context.h>
+#include <interrupt_mgmt.h>
+#include <platform_def.h>
+#include <psci.h>
+
+/*******************************************************************************
+ * OPTEE PM state information e.g. OPTEE is suspended, uninitialised etc
+ * and macros to access the state information in the per-cpu 'state' flags
+ ******************************************************************************/
+#define OPTEE_PSTATE_OFF		0
+#define OPTEE_PSTATE_ON			1
+#define OPTEE_PSTATE_SUSPEND		2
+#define OPTEE_PSTATE_SHIFT		0
+#define OPTEE_PSTATE_MASK		0x3
+#define get_optee_pstate(state)	((state >> OPTEE_PSTATE_SHIFT) & \
+				 OPTEE_PSTATE_MASK)
+#define clr_optee_pstate(state)	(state &= ~(OPTEE_PSTATE_MASK \
+					    << OPTEE_PSTATE_SHIFT))
+#define set_optee_pstate(st, pst) do {					       \
+					clr_optee_pstate(st);		       \
+					st |= (pst & OPTEE_PSTATE_MASK) <<     \
+						OPTEE_PSTATE_SHIFT;	       \
+				} while (0)
+
+
+/*******************************************************************************
+ * OPTEE execution state information i.e. aarch32 or aarch64
+ ******************************************************************************/
+#define OPTEE_AARCH32		MODE_RW_32
+#define OPTEE_AARCH64		MODE_RW_64
+
+/*******************************************************************************
+ * The OPTEED should know the type of OPTEE
+ ******************************************************************************/
+#define OPTEE_TYPE_UP		PSCI_TOS_NOT_UP_MIG_CAP
+#define OPTEE_TYPE_UPM		PSCI_TOS_UP_MIG_CAP
+#define OPTEE_TYPE_MP		PSCI_TOS_NOT_PRESENT_MP
+
+/*******************************************************************************
+ * OPTEE migrate type information as known to the OPTEED. We assume that
+ * the OPTEED is dealing with an MP Secure Payload.
+ ******************************************************************************/
+#define OPTEE_MIGRATE_INFO		OPTEE_TYPE_MP
+
+/*******************************************************************************
+ * Number of cpus that the present on this platform. TODO: Rely on a topology
+ * tree to determine this in the future to avoid assumptions about mpidr
+ * allocation
+ ******************************************************************************/
+#define OPTEED_CORE_COUNT		PLATFORM_CORE_COUNT
+
+/*******************************************************************************
+ * Constants that allow assembler code to preserve callee-saved registers of the
+ * C runtime context while performing a security state switch.
+ ******************************************************************************/
+#define OPTEED_C_RT_CTX_X19		0x0
+#define OPTEED_C_RT_CTX_X20		0x8
+#define OPTEED_C_RT_CTX_X21		0x10
+#define OPTEED_C_RT_CTX_X22		0x18
+#define OPTEED_C_RT_CTX_X23		0x20
+#define OPTEED_C_RT_CTX_X24		0x28
+#define OPTEED_C_RT_CTX_X25		0x30
+#define OPTEED_C_RT_CTX_X26		0x38
+#define OPTEED_C_RT_CTX_X27		0x40
+#define OPTEED_C_RT_CTX_X28		0x48
+#define OPTEED_C_RT_CTX_X29		0x50
+#define OPTEED_C_RT_CTX_X30		0x58
+#define OPTEED_C_RT_CTX_SCR		0x60
+#define OPTEED_C_RT_CTX_SIZE		0x70
+#define OPTEED_C_RT_CTX_ENTRIES		(OPTEED_C_RT_CTX_SIZE >> DWORD_SHIFT)
+
+#ifndef __ASSEMBLY__
+
+#include <cassert.h>
+#include <stdint.h>
+
+/*
+ * The number of arguments to save during a SMC call for OPTEE.
+ * Currently only x1 and x2 are used by OPTEE.
+ */
+#define OPTEE_NUM_ARGS	0x2
+
+/* AArch64 callee saved general purpose register context structure. */
+DEFINE_REG_STRUCT(c_rt_regs, OPTEED_C_RT_CTX_ENTRIES);
+
+/*
+ * Compile time assertion to ensure that both the compiler and linker
+ * have the same double word aligned view of the size of the C runtime
+ * register context.
+ */
+CASSERT(OPTEED_C_RT_CTX_SIZE == sizeof(c_rt_regs_t),	\
+	assert_spd_c_rt_regs_size_mismatch);
+
+/*******************************************************************************
+ * Structure which helps the OPTEED to maintain the per-cpu state of OPTEE.
+ * 'state'          - collection of flags to track OPTEE state e.g. on/off
+ * 'mpidr'          - mpidr to associate a context with a cpu
+ * 'c_rt_ctx'       - stack address to restore C runtime context from after
+ *                    returning from a synchronous entry into OPTEE.
+ * 'cpu_ctx'        - space to maintain OPTEE architectural state
+ ******************************************************************************/
+typedef struct optee_context {
+	uint32_t state;
+	uint64_t mpidr;
+	uint64_t c_rt_ctx;
+	cpu_context_t cpu_ctx;
+} optee_context_t;
+
+/* OPTEED power management handlers */
+extern const spd_pm_ops_t opteed_pm;
+
+/*******************************************************************************
+ * Forward declarations
+ ******************************************************************************/
+struct optee_vectors;
+
+/*******************************************************************************
+ * Function & Data prototypes
+ ******************************************************************************/
+uint64_t opteed_enter_sp(uint64_t *c_rt_ctx);
+void __dead2 opteed_exit_sp(uint64_t c_rt_ctx, uint64_t ret);
+uint64_t opteed_synchronous_sp_entry(optee_context_t *optee_ctx);
+void __dead2 opteed_synchronous_sp_exit(optee_context_t *optee_ctx, uint64_t ret);
+int32_t opteed_init_secure_context(uint64_t entrypoint,
+					uint32_t rw,
+					uint64_t mpidr,
+					optee_context_t *optee_ctx);
+extern optee_context_t opteed_sp_context[OPTEED_CORE_COUNT];
+extern uint32_t opteed_rw;
+extern struct optee_vectors *optee_vectors;
+#endif /*__ASSEMBLY__*/
+
+#endif /* __OPTEED_PRIVATE_H__ */
diff --git a/services/spd/opteed/teesmc.h b/services/spd/opteed/teesmc.h
new file mode 100644
index 0000000..995d2fc
--- /dev/null
+++ b/services/spd/opteed/teesmc.h
@@ -0,0 +1,696 @@
+/*
+ * Copyright (c) 2014, Linaro Limited
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright notice,
+ *    this list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef TEESMC_H
+#define TEESMC_H
+
+#ifndef ASM
+/*
+ * This section depends on uint64_t, uint32_t uint8_t already being
+ * defined. Since this file is used in several different environments
+ * (secure world OS and normal world Linux kernel to start with) where
+ * stdint.h may not be available it's the responsibility of the one
+ * including this file to provide those types.
+ */
+
+/*
+ * Trusted OS SMC interface.
+ *
+ * The SMC interface follows SMC Calling Convention
+ * (ARM_DEN0028A_SMC_Calling_Convention).
+ *
+ * The primary objective of this API is to provide a transport layer on
+ * which a Global Platform compliant TEE interfaces can be deployed. But the
+ * interface can also be used for other implementations.
+ *
+ * This file is divided in two parts.
+ * Part 1 deals with passing parameters to Trusted Applications running in
+ * a trusted OS in secure world.
+ * Part 2 deals with the lower level handling of the SMC.
+ */
+
+/*
+ *******************************************************************************
+ * Part 1 - passing parameters to Trusted Applications
+ *******************************************************************************
+ */
+
+/*
+ * Same values as TEE_PARAM_* from TEE Internal API
+ */
+#define TEESMC_ATTR_TYPE_NONE		0
+#define TEESMC_ATTR_TYPE_VALUE_INPUT	1
+#define TEESMC_ATTR_TYPE_VALUE_OUTPUT	2
+#define TEESMC_ATTR_TYPE_VALUE_INOUT	3
+#define TEESMC_ATTR_TYPE_MEMREF_INPUT	5
+#define TEESMC_ATTR_TYPE_MEMREF_OUTPUT	6
+#define TEESMC_ATTR_TYPE_MEMREF_INOUT	7
+
+#define TEESMC_ATTR_TYPE_MASK		0x7
+
+/*
+ * Meta parameter to be absorbed by the Secure OS and not passed
+ * to the Trusted Application.
+ *
+ * One example of this is a struct teesmc_meta_open_session which
+ * is added to TEESMC{32,64}_CMD_OPEN_SESSION.
+ */
+#define TEESMC_ATTR_META		0x8
+
+/*
+ * Used as an indication from normal world of compatible cache usage.
+ * 'I' stands for inner cache and 'O' for outer cache.
+ */
+#define TEESMC_ATTR_CACHE_I_NONCACHE	0x0
+#define TEESMC_ATTR_CACHE_I_WRITE_THR	0x1
+#define TEESMC_ATTR_CACHE_I_WRITE_BACK	0x2
+#define TEESMC_ATTR_CACHE_O_NONCACHE	0x0
+#define TEESMC_ATTR_CACHE_O_WRITE_THR	0x4
+#define TEESMC_ATTR_CACHE_O_WRITE_BACK	0x8
+
+#define TEESMC_ATTR_CACHE_DEFAULT	(TEESMC_ATTR_CACHE_I_WRITE_BACK | \
+					 TEESMC_ATTR_CACHE_O_WRITE_BACK)
+
+#define TEESMC_ATTR_CACHE_SHIFT		4
+#define TEESMC_ATTR_CACHE_MASK		0xf
+
+#define TEESMC_CMD_OPEN_SESSION		0
+#define TEESMC_CMD_INVOKE_COMMAND	1
+#define TEESMC_CMD_CLOSE_SESSION	2
+#define TEESMC_CMD_CANCEL		3
+
+/**
+ * struct teesmc32_param_memref - memory reference
+ * @buf_ptr: Address of the buffer
+ * @size: Size of the buffer
+ *
+ * Secure and normal world communicates pointer via physical address instead of
+ * the virtual address with is usually used for pointers. This is because
+ * Secure and normal world has completely independant memory mapping. Normal
+ * world can even have a hypervisor which need to translate the guest
+ * physical address (AKA IPA in ARM lingo) to a real physical address
+ * before passing the structure to secure world.
+ */
+struct teesmc32_param_memref {
+	uint32_t buf_ptr;
+	uint32_t size;
+};
+
+/**
+ * struct teesmc32_param_memref - memory reference
+ * @buf_ptr: Address of the buffer
+ * @size: Size of the buffer
+ *
+ * See description of struct teesmc32_param_memref.
+ */
+struct teesmc64_param_memref {
+	uint64_t buf_ptr;
+	uint64_t size;
+};
+
+/**
+ * struct teesmc32_param_value - values
+ * @a: first value
+ * @b: second value
+ */
+struct teesmc32_param_value {
+	uint32_t a;
+	uint32_t b;
+};
+
+/**
+ * struct teesmc64_param_value - values
+ * @a: first value
+ * @b: second value
+ */
+struct teesmc64_param_value {
+	uint64_t a;
+	uint64_t b;
+};
+
+/**
+ * struct teesmc32_param - parameter
+ * @attr: attributes
+ * @memref: a memory reference
+ * @value: a value
+ *
+ * attr & TEESMC_ATTR_TYPE_MASK indicates if memref or value is used in the
+ * union. TEESMC_ATTR_TYPE_VALUE_* indicates value and
+ * TEESMC_ATTR_TYPE_MEMREF_* indicates memref. TEESMC_ATTR_TYPE_NONE
+ * indicates that none of the members are used.
+ */
+struct teesmc32_param {
+	uint32_t attr;
+	union {
+		struct teesmc32_param_memref memref;
+		struct teesmc32_param_value value;
+	} u;
+};
+
+/**
+ * struct teesmc64_param - parameter
+ * @attr: attributes
+ * @memref: a memory reference
+ * @value: a value
+ *
+ * See description of union teesmc32_param.
+ */
+struct teesmc64_param {
+	uint64_t attr;
+	union {
+		struct teesmc64_param_memref memref;
+		struct teesmc64_param_value value;
+	} u;
+};
+
+/**
+ * struct teesmc32_arg - SMC argument for Trusted OS
+ * @cmd: Command, one of TEESMC_CMD_*
+ * @ta_func: Trusted Application function, specific to the Trusted Application,
+ *	     used if cmd == TEESMC_CMD_INVOKE_COMMAND
+ * @session: In parameter for all TEESMC_CMD_* except
+ *	     TEESMC_CMD_OPEN_SESSION where it's an output paramter instead
+ * @ret: return value
+ * @ret_origin: origin of the return value
+ * @num_params: number of parameters supplied to the OS Command
+ * @params: the parameters supplied to the OS Command
+ *
+ * All normal SMC calls to Trusted OS uses this struct. If cmd requires
+ * further information than what these field holds it can be passed as a
+ * parameter tagged as meta (setting the TEESMC_ATTR_META bit in
+ * corresponding param_attrs). This is used for TEESMC_CMD_OPEN_SESSION
+ * to pass a struct teesmc32_meta_open_session which is needed find the
+ * Trusted Application and to indicate the credentials of the client.
+ */
+struct teesmc32_arg {
+	uint32_t cmd;
+	uint32_t ta_func;
+	uint32_t session;
+	uint32_t ret;
+	uint32_t ret_origin;
+	uint32_t num_params;
+#if 0
+	/*
+	 * Commented out elements used to visualize the layout dynamic part
+	 * of the struct. Note that these fields are not available at all
+	 * if num_params == 0.
+	 *
+	 * params is accessed through the macro TEESMC32_GET_PARAMS
+	 */
+
+	struct teesmc32_param params[num_params];
+#endif
+};
+
+/**
+ * TEESMC32_GET_PARAMS - return pointer to union teesmc32_param *
+ *
+ * @x: Pointer to a struct teesmc32_arg
+ *
+ * Returns a pointer to the params[] inside a struct teesmc32_arg.
+ */
+#define TEESMC32_GET_PARAMS(x) \
+	(struct teesmc32_param *)(((struct teesmc32_arg *)(x)) + 1)
+
+/**
+ * TEESMC32_GET_ARG_SIZE - return size of struct teesmc32_arg
+ *
+ * @num_params: Number of parameters embedded in the struct teesmc32_arg
+ *
+ * Returns the size of the struct teesmc32_arg together with the number
+ * of embedded paramters.
+ */
+#define TEESMC32_GET_ARG_SIZE(num_params) \
+	(sizeof(struct teesmc32_arg) + \
+	 sizeof(struct teesmc32_param) * (num_params))
+
+/**
+ * struct teesmc64_arg - SMC argument for Trusted OS
+ * @cmd: OS Command, one of TEESMC_CMD_*
+ * @ta_func: Trusted Application function, specific to the Trusted Application
+ * @session: In parameter for all TEESMC_CMD_* but
+ *	     TEESMC_CMD_OPEN_SESSION
+ * @ret: return value
+ * @ret_origin: origin of the return value
+ * @num_params: number of parameters supplied to the OS Command
+ * @params: the parameters supplied to the OS Command
+ *
+ * See description of struct teesmc32_arg.
+ */
+struct teesmc64_arg {
+	uint64_t cmd;
+	uint64_t ta_func;
+	uint64_t session;
+	uint64_t ret;
+	uint64_t ret_origin;
+	uint64_t num_params;
+#if 0
+	/*
+	 * Commented out elements used to visualize the layout dynamic part
+	 * of the struct. Note that these fields are not available at all
+	 * if num_params == 0.
+	 *
+	 * params is accessed through the macro TEESMC64_GET_PARAMS
+	 */
+
+	union teesmc64_param params[num_params];
+#endif
+};
+
+/**
+ * TEESMC64_GET_PARAMS - return pointer to union teesmc64_param *
+ *
+ * @x: Pointer to a struct teesmc64_arg
+ *
+ * Returns a pointer to the params[] inside a struct teesmc64_arg.
+ */
+#define TEESMC64_GET_PARAMS(x) \
+	(struct teesmc64_param *)(((struct teesmc64_arg *)(x)) + 1)
+
+/**
+ * TEESMC64_GET_ARG_SIZE - return size of struct teesmc64_arg
+ *
+ * @num_params: Number of parameters embedded in the struct teesmc64_arg
+ *
+ * Returns the size of the struct teesmc64_arg together with the number
+ * of embedded paramters.
+ */
+#define TEESMC64_GET_ARG_SIZE(num_params) \
+	(sizeof(struct teesmc64_arg) + \
+	 sizeof(union teesmc64_param) * (num_params))
+
+#define TEESMC_UUID_LEN	16
+
+/**
+ * struct teesmc_meta_open_session - additional parameters for
+ *				     TEESMC32_CMD_OPEN_SESSION and
+ *				     TEESMC64_CMD_OPEN_SESSION
+ * @uuid: UUID of the Trusted Application
+ * @clnt_uuid: UUID of client
+ * @clnt_login: Login class of client, TEE_LOGIN_* if being Global Platform
+ *		compliant
+ *
+ * This struct is passed in the first parameter as an input memref tagged
+ * as meta on an TEESMC{32,64}_CMD_OPEN_SESSION cmd. It's important
+ * that it really is the first parameter to make it easy for an eventual
+ * hypervisor to inspect and possibly update clnt_* values.
+ */
+struct teesmc_meta_open_session {
+	uint8_t uuid[TEESMC_UUID_LEN];
+	uint8_t clnt_uuid[TEESMC_UUID_LEN];
+	uint32_t clnt_login;
+};
+
+
+#endif /*!ASM*/
+
+/*
+ *******************************************************************************
+ * Part 2 - low level SMC interaction
+ *******************************************************************************
+ */
+
+#define TEESMC_32			0
+#define TEESMC_64			0x40000000
+#define TEESMC_FAST_CALL		0x80000000
+#define TEESMC_STD_CALL			0
+
+#define TEESMC_OWNER_MASK		0x3F
+#define TEESMC_OWNER_SHIFT		24
+
+#define TEESMC_FUNC_MASK		0xFFFF
+
+#define TEESMC_IS_FAST_CALL(smc_val)	((smc_val) & TEESMC_FAST_CALL)
+#define TEESMC_IS_64(smc_val)		((smc_val) & TEESMC_64)
+#define TEESMC_FUNC_NUM(smc_val)	((smc_val) & TEESMC_FUNC_MASK)
+#define TEESMC_OWNER_NUM(smc_val)	(((smc_val) >> TEESMC_OWNER_SHIFT) & \
+					 TEESMC_OWNER_MASK)
+
+#define TEESMC_CALL_VAL(type, calling_convention, owner, func_num) \
+			((type) | (calling_convention) | \
+			(((owner) & TEESMC_OWNER_MASK) << TEESMC_OWNER_SHIFT) |\
+			((func_num) & TEESMC_FUNC_MASK))
+
+#define TEESMC_OWNER_ARCH		0
+#define TEESMC_OWNER_CPU		1
+#define TEESMC_OWNER_SIP		2
+#define TEESMC_OWNER_OEM		3
+#define TEESMC_OWNER_STANDARD		4
+#define TEESMC_OWNER_TRUSTED_APP	48
+#define TEESMC_OWNER_TRUSTED_OS		50
+
+#define TEESMC_OWNER_TRUSTED_OS_OPTEED	62
+#define TEESMC_OWNER_TRUSTED_OS_API	63
+
+/*
+ * Function specified by SMC Calling convention.
+ */
+#define TEESMC32_FUNCID_CALLS_COUNT	0xFF00
+#define TEESMC32_CALLS_COUNT \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_API, \
+			TEESMC32_FUNCID_CALLS_COUNT)
+
+/*
+ * Function specified by SMC Calling convention
+ *
+ * Return one of the following UIDs if using API specified in this file
+ * without further extentions:
+ * 65cb6b93-af0c-4617-8ed6-644a8d1140f8 : Only 32 bit calls are supported
+ * 65cb6b93-af0c-4617-8ed6-644a8d1140f9 : Both 32 and 64 bit calls are supported
+ */
+#define TEESMC_UID_R0			0x65cb6b93
+#define TEESMC_UID_R1			0xaf0c4617
+#define TEESMC_UID_R2			0x8ed6644a
+#define TEESMC_UID32_R3			0x8d1140f8
+#define TEESMC_UID64_R3			0x8d1140f9
+#define TEESMC32_FUNCID_CALLS_UID	0xFF01
+#define TEESMC32_CALLS_UID \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_API, \
+			TEESMC32_FUNCID_CALLS_UID)
+
+/*
+ * Function specified by SMC Calling convention
+ *
+ * Returns 1.0 if using API specified in this file without further extentions.
+ */
+#define TEESMC_REVISION_MAJOR	1
+#define TEESMC_REVISION_MINOR	0
+#define TEESMC32_FUNCID_CALLS_REVISION	0xFF03
+#define TEESMC32_CALLS_REVISION \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_API, \
+			TEESMC32_FUNCID_CALLS_REVISION)
+
+/*
+ * Get UUID of Trusted OS.
+ *
+ * Used by non-secure world to figure out which Trusted OS is installed.
+ * Note that returned UUID is the UUID of the Trusted OS, not of the API.
+ *
+ * Returns UUID in r0-4/w0-4 in the same way as TEESMC32_CALLS_UID
+ * described above.
+ */
+#define TEESMC_FUNCID_GET_OS_UUID	0
+#define TEESMC32_CALL_GET_OS_UUID \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, TEESMC_OWNER_TRUSTED_OS, \
+			TEESMC_FUNCID_GET_OS_UUID)
+
+/*
+ * Get revision of Trusted OS.
+ *
+ * Used by non-secure world to figure out which version of the Trusted OS
+ * is installed. Note that the returned revision is the revision of the
+ * Trusted OS, not of the API.
+ *
+ * Returns revision in r0-1/w0-1 in the same way as TEESMC32_CALLS_REVISION
+ * described above.
+ */
+#define TEESMC_FUNCID_GET_OS_REVISION	1
+#define TEESMC32_CALL_GET_OS_REVISION \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, TEESMC_OWNER_TRUSTED_OS, \
+			TEESMC_FUNCID_GET_OS_REVISION)
+
+
+
+/*
+ * Call with struct teesmc32_arg as argument
+ *
+ * Call register usage:
+ * r0/x0	SMC Function ID, TEESMC32_CALL_WITH_ARG
+ * r1/x1	Physical pointer to a struct teesmc32_arg
+ * r2-6/x2-6	Not used
+ * r7/x7	Hypervisor Client ID register
+ *
+ * Normal return register usage:
+ * r0/x0	Return value, TEESMC_RETURN_*
+ * r1-3/x1-3	Not used
+ * r4-7/x4-7	Preserved
+ *
+ * Ebusy return register usage:
+ * r0/x0	Return value, TEESMC_RETURN_EBUSY
+ * r1-3/x1-3	Preserved
+ * r4-7/x4-7	Preserved
+ *
+ * RPC return register usage:
+ * r0/x0	Return value, TEESMC_RETURN_IS_RPC(val)
+ * r1-2/x1-2	RPC parameters
+ * r3-7/x3-7	Resume information, must be preserved
+ *
+ * Possible return values:
+ * TEESMC_RETURN_UNKNOWN_FUNCTION	Trusted OS does not recognize this
+ *					function.
+ * TEESMC_RETURN_OK			Call completed, result updated in
+ *					the previously supplied struct
+ *					teesmc32_arg.
+ * TEESMC_RETURN_EBUSY			Trusted OS busy, try again later.
+ * TEESMC_RETURN_EBADADDR		Bad physcial pointer to struct
+ *					teesmc32_arg.
+ * TEESMC_RETURN_EBADCMD		Bad/unknown cmd in struct teesmc32_arg
+ * TEESMC_RETURN_IS_RPC()		Call suspended by RPC call to normal
+ *					world.
+ */
+#define TEESMC_FUNCID_CALL_WITH_ARG	2
+#define TEESMC32_CALL_WITH_ARG \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_STD_CALL, TEESMC_OWNER_TRUSTED_OS, \
+	TEESMC_FUNCID_CALL_WITH_ARG)
+/* Same as TEESMC32_CALL_WITH_ARG but a "fast call". */
+#define TEESMC32_FASTCALL_WITH_ARG \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, TEESMC_OWNER_TRUSTED_OS, \
+	TEESMC_FUNCID_CALL_WITH_ARG)
+
+/*
+ * Call with struct teesmc64_arg as argument
+ *
+ * See description of TEESMC32_CALL_WITH_ARG above, uses struct
+ * teesmc64_arg in x1 instead.
+ */
+#define TEESMC64_CALL_WITH_ARG \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_STD_CALL, TEESMC_OWNER_TRUSTED_OS, \
+	TEESMC_FUNCID_CALL_WITH_ARG)
+/* Same as TEESMC64_CALL_WITH_ARG but a "fast call". */
+#define TEESMC64_FASTCALL_WITH_ARG \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_FAST_CALL, TEESMC_OWNER_TRUSTED_OS, \
+	TEESMC_FUNCID_CALL_WITH_ARG)
+
+/*
+ * Resume from RPC (for example after processing an IRQ)
+ *
+ * Call register usage:
+ * r0/x0	SMC Function ID,
+ *		TEESMC32_CALL_RETURN_FROM_RPC or
+ *		TEESMC32_FASTCALL_RETURN_FROM_RPC
+ * r1-3/x1-3	Value of r1-3/x1-3 when TEESMC32_CALL_WITH_ARG returned
+ *		TEESMC_RETURN_RPC in r0/x0
+ *
+ * Return register usage is the same as for TEESMC32_CALL_WITH_ARG above.
+ *
+ * Possible return values
+ * TEESMC_RETURN_UNKNOWN_FUNCTION	Trusted OS does not recognize this
+ *					function.
+ * TEESMC_RETURN_OK			Original call completed, result
+ *					updated in the previously supplied.
+ *					struct teesmc32_arg
+ * TEESMC_RETURN_RPC			Call suspended by RPC call to normal
+ *					world.
+ * TEESMC_RETURN_EBUSY			Trusted OS busy, try again later.
+ * TEESMC_RETURN_ERESUME		Resume failed, the opaque resume
+ *					information was corrupt.
+ */
+#define TEESMC_FUNCID_RETURN_FROM_RPC	3
+#define TEESMC32_CALL_RETURN_FROM_RPC \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_STD_CALL, TEESMC_OWNER_TRUSTED_OS, \
+			TEESMC_FUNCID_RETURN_FROM_RPC)
+/* Same as TEESMC32_CALL_RETURN_FROM_RPC but a "fast call". */
+#define TEESMC32_FASTCALL_RETURN_FROM_RPC \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_STD_CALL, TEESMC_OWNER_TRUSTED_OS, \
+			TEESMC_FUNCID_RETURN_FROM_RPC)
+
+/*
+ * Resume from RPC (for example after processing an IRQ)
+ *
+ * See description of TEESMC32_CALL_RETURN_FROM_RPC above, used when
+ * it's a 64bit call that has returned.
+ */
+#define TEESMC64_CALL_RETURN_FROM_RPC \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_STD_CALL, TEESMC_OWNER_TRUSTED_OS, \
+			TEESMC_FUNCID_RETURN_FROM_RPC)
+/* Same as TEESMC64_CALL_RETURN_FROM_RPC but a "fast call". */
+#define TEESMC64_FASTCALL_RETURN_FROM_RPC \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_STD_CALL, TEESMC_OWNER_TRUSTED_OS, \
+			TEESMC_FUNCID_RETURN_FROM_RPC)
+
+#define TEESMC_RETURN_RPC_PREFIX_MASK	0xFFFF0000
+#define TEESMC_RETURN_RPC_PREFIX	0xFFFF0000
+#define TEESMC_RETURN_RPC_FUNC_MASK	0x0000FFFF
+
+#define TEESMC_RETURN_GET_RPC_FUNC(ret)	((ret) & TEESMC_RETURN_RPC_FUNC_MASK)
+
+#define TEESMC_RPC_VAL(func)		((func) | TEESMC_RETURN_RPC_PREFIX)
+
+/*
+ * Allocate argument memory for RPC parameter passing.
+ * Argument memory is used to hold a struct teesmc32_arg.
+ *
+ * "Call" register usage:
+ * r0/x0	This value, TEESMC_RETURN_RPC_ALLOC
+ * r1/x1	Size in bytes of required argument memory
+ * r2-7/x2-7	Resume information, must be preserved
+ *
+ * "Return" register usage:
+ * r0/x0	SMC Function ID, TEESMC32_CALL_RETURN_FROM_RPC if it was an
+ *		AArch32 SMC return or TEESMC64_CALL_RETURN_FROM_RPC for
+ *		AArch64 SMC return
+ * r1/x1	Physical pointer to allocated argument memory, 0 if size
+ *		was 0 or if memory can't be allocated
+ * r2-7/x2-7	Preserved
+ */
+#define TEESMC_RPC_FUNC_ALLOC_ARG	0
+#define TEESMC_RETURN_RPC_ALLOC_ARG	\
+	TEESMC_RPC_VAL(TEESMC_RPC_FUNC_ALLOC_ARG)
+
+/*
+ * Allocate payload memory for RPC parameter passing.
+ * Payload memory is used to hold the memory referred to by struct
+ * teesmc32_param_memref.
+ *
+ * "Call" register usage:
+ * r0/x0	This value, TEESMC_RETURN_RPC_ALLOC
+ * r1/x1	Size in bytes of required payload memory
+ * r2-7/x2-7	Resume information, must be preserved
+ *
+ * "Return" register usage:
+ * r0/x0	SMC Function ID, TEESMC32_CALL_RETURN_FROM_RPC if it was an
+ *		AArch32 SMC return or TEESMC64_CALL_RETURN_FROM_RPC for
+ *		AArch64 SMC return
+ * r1/x1	Physical pointer to allocated payload memory, 0 if size
+ *		was 0 or if memory can't be allocated
+ * r2-7/x2-7	Preserved
+ */
+#define TEESMC_RPC_FUNC_ALLOC_PAYLOAD	1
+#define TEESMC_RETURN_RPC_ALLOC_PAYLOAD	\
+	TEESMC_RPC_VAL(TEESMC_RPC_FUNC_ALLOC_PAYLOAD)
+
+/*
+ * Free memory previously allocated by TEESMC_RETURN_RPC_ALLOC_ARG.
+ *
+ * "Call" register usage:
+ * r0/x0	This value, TEESMC_RETURN_RPC_FREE
+ * r1/x1	Physical pointer to previously allocated argument memory
+ * r2-7/x2-7	Resume information, must be preserved
+ *
+ * "Return" register usage:
+ * r0/x0	SMC Function ID, TEESMC32_CALL_RETURN_FROM_RPC if it was an
+ *		AArch32 SMC return or TEESMC64_CALL_RETURN_FROM_RPC for
+ *		AArch64 SMC return
+ * r1/x1	Not used
+ * r2-7/x2-7	Preserved
+ */
+#define TEESMC_RPC_FUNC_FREE_ARG	2
+#define TEESMC_RETURN_RPC_FREE_ARG	TEESMC_RPC_VAL(TEESMC_RPC_FUNC_FREE_ARG)
+
+/*
+ * Free memory previously allocated by TEESMC_RETURN_RPC_ALLOC_PAYLOAD.
+ *
+ * "Call" register usage:
+ * r0/x0	This value, TEESMC_RETURN_RPC_FREE
+ * r1/x1	Physical pointer to previously allocated payload memory
+ * r3-7/x3-7	Resume information, must be preserved
+ *
+ * "Return" register usage:
+ * r0/x0	SMC Function ID, TEESMC32_CALL_RETURN_FROM_RPC if it was an
+ *		AArch32 SMC return or TEESMC64_CALL_RETURN_FROM_RPC for
+ *		AArch64 SMC return
+ * r1-2/x1-2	Not used
+ * r3-7/x3-7	Preserved
+ */
+#define TEESMC_RPC_FUNC_FREE_PAYLOAD	3
+#define TEESMC_RETURN_RPC_FREE_PAYLOAD	\
+	TEESMC_RPC_VAL(TEESMC_RPC_FUNC_FREE_PAYLOAD)
+
+/*
+ * Deliver an IRQ in normal world.
+ *
+ * "Call" register usage:
+ * r0/x0	TEESMC_RETURN_RPC_IRQ
+ * r1-7/x1-7	Resume information, must be preserved
+ *
+ * "Return" register usage:
+ * r0/x0	SMC Function ID, TEESMC32_CALL_RETURN_FROM_RPC if it was an
+ *		AArch32 SMC return or TEESMC64_CALL_RETURN_FROM_RPC for
+ *		AArch64 SMC return
+ * r1-7/x1-7	Preserved
+ */
+#define TEESMC_RPC_FUNC_IRQ		4
+#define TEESMC_RETURN_RPC_IRQ		TEESMC_RPC_VAL(TEESMC_RPC_FUNC_IRQ)
+
+/*
+ * Do an RPC request. The supplied struct teesmc{32,64}_arg tells which
+ * request to do and the paramters for the request. The following fields
+ * are used (the rest are unused):
+ * - cmd		the Request ID
+ * - ret		return value of the request, filled in by normal world
+ * - num_params		number of parameters for the request
+ * - params		the parameters
+ * - param_attrs	attributes of the parameters
+ *
+ * "Call" register usage:
+ * r0/x0	TEESMC_RETURN_RPC_CMD
+ * r1/x1	Physical pointer to a struct teesmc32_arg if returning from
+ *		a AArch32 SMC or a struct teesmc64_arg if returning from a
+ *		AArch64 SMC, must be preserved, only the data should
+ *		be updated
+ * r2-7/x2-7	Resume information, must be preserved
+ *
+ * "Return" register usage:
+ * r0/x0	SMC Function ID, TEESMC32_CALL_RETURN_FROM_RPC if it was an
+ *		AArch32 SMC return or TEESMC64_CALL_RETURN_FROM_RPC for
+ *		AArch64 SMC return
+ * r1-7/x1-7	Preserved
+ */
+#define TEESMC_RPC_FUNC_CMD		5
+#define TEESMC_RETURN_RPC_CMD		TEESMC_RPC_VAL(TEESMC_RPC_FUNC_CMD)
+
+
+/* Returned in r0 */
+#define TEESMC_RETURN_UNKNOWN_FUNCTION	0xFFFFFFFF
+
+/* Returned in r0 only from Trusted OS functions */
+#define TEESMC_RETURN_OK		0x0
+#define TEESMC_RETURN_EBUSY		0x1
+#define TEESMC_RETURN_ERESUME		0x2
+#define TEESMC_RETURN_EBADADDR		0x3
+#define TEESMC_RETURN_EBADCMD		0x4
+#define TEESMC_RETURN_IS_RPC(ret) \
+	(((ret) & TEESMC_RETURN_RPC_PREFIX_MASK) == TEESMC_RETURN_RPC_PREFIX)
+
+/*
+ * Returned in r1 by Trusted OS functions if r0 = TEESMC_RETURN_RPC
+ */
+#define TEESMC_RPC_REQUEST_IRQ		0x0
+
+#endif /* TEESMC_H */
diff --git a/services/spd/opteed/teesmc_opteed.h b/services/spd/opteed/teesmc_opteed.h
new file mode 100644
index 0000000..22db112
--- /dev/null
+++ b/services/spd/opteed/teesmc_opteed.h
@@ -0,0 +1,161 @@
+/*
+ * Copyright (c) 2014, STMicroelectronics All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright notice,
+ * this list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright notice,
+ * this list of conditions and the following disclaimer in the documentation
+ * and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
+ * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
+ * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+ * POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef TEESMC_OPTEED_H
+#define TEESMC_OPTEED_H
+
+/*
+ * This file specify SMC function IDs used when returning from TEE to the
+ * secure monitor.
+ */
+
+/*
+ * Issued when returning from initial entry.
+ *
+ * Register usage:
+ * r0/x0	SMC Function ID, TEESMC32_OPTEED_RETURN_ENTRY_DONE or
+ *		TEESMC64_OPTEED_RETURN_ENTRY_DONE
+ * r1/x1	Pointer to entry vector
+ */
+#define TEESMC_OPTEED_FUNCID_RETURN_ENTRY_DONE		0
+#define TEESMC32_OPTEED_RETURN_ENTRY_DONE \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_ENTRY_DONE)
+#define TEESMC64_OPTEED_RETURN_ENTRY_DONE \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_ENTRY_DONE)
+
+/*
+ * Issued when returning from "cpu_on" vector
+ *
+ * Register usage:
+ * r0/x0	SMC Function ID, TEESMC32_OPTEED_RETURN_ON_DONE or
+ *		TEESMC64_OPTEED_RETURN_ON_DONE
+ * r1/x1	0 on success and anything else to indicate error condition
+ */
+#define TEESMC_OPTEED_FUNCID_RETURN_ON_DONE		1
+#define TEESMC32_OPTEED_RETURN_ON_DONE \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_ON_DONE)
+#define TEESMC64_OPTEED_RETURN_ON_DONE \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_ON_DONE)
+
+/*
+ * Issued when returning from "cpu_off" vector
+ *
+ * Register usage:
+ * r0/x0	SMC Function ID, TEESMC32_OPTEED_RETURN_OFF_DONE or
+ *		TEESMC64_OPTEED_RETURN_OFF_DONE
+ * r1/x1	0 on success and anything else to indicate error condition
+ */
+#define TEESMC_OPTEED_FUNCID_RETURN_OFF_DONE		2
+#define TEESMC32_OPTEED_RETURN_OFF_DONE \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_OFF_DONE)
+#define TEESMC64_OPTEED_RETURN_OFF_DONE \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_OFF_DONE)
+
+/*
+ * Issued when returning from "cpu_suspend" vector
+ *
+ * Register usage:
+ * r0/x0	SMC Function ID, TEESMC32_OPTEED_RETURN_SUSPEND_DONE or
+ *		TEESMC64_OPTEED_RETURN_SUSPEND_DONE
+ * r1/x1	0 on success and anything else to indicate error condition
+ */
+#define TEESMC_OPTEED_FUNCID_RETURN_SUSPEND_DONE	3
+#define TEESMC32_OPTEED_RETURN_SUSPEND_DONE \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_SUSPEND_DONE)
+#define TEESMC64_OPTEED_RETURN_SUSPEND_DONE \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_SUSPEND_DONE)
+
+/*
+ * Issued when returning from "cpu_resume" vector
+ *
+ * Register usage:
+ * r0/x0	SMC Function ID, TEESMC32_OPTEED_RETURN_RESUME_DONE or
+ *		TEESMC64_OPTEED_RETURN_RESUME_DONE
+ * r1/x1	0 on success and anything else to indicate error condition
+ */
+#define TEESMC_OPTEED_FUNCID_RETURN_RESUME_DONE		4
+#define TEESMC32_OPTEED_RETURN_RESUME_DONE \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_RESUME_DONE)
+#define TEESMC64_OPTEED_RETURN_RESUME_DONE \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_RESUME_DONE)
+
+/*
+ * Issued when returning from "std_smc" or "fast_smc" vector
+ *
+ * Register usage:
+ * r0/x0	SMC Function ID, TEESMC32_OPTEED_RETURN_CALL_DONE or
+ *		TEESMC64_OPTEED_RETURN_CALL_DONE
+ * r1-4/x1-4	Return value 0-3 which will passed to normal world in
+ *		r0-3/x0-3
+ */
+#define TEESMC_OPTEED_FUNCID_RETURN_CALL_DONE		5
+#define TEESMC32_OPTEED_RETURN_CALL_DONE \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_CALL_DONE)
+#define TEESMC64_OPTEED_RETURN_CALL_DONE \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_CALL_DONE)
+
+/*
+ * Issued when returning from "fiq" vector
+ *
+ * Register usage:
+ * r0/x0	SMC Function ID, TEESMC32_OPTEED_RETURN_FIQ_DONE or
+ *		TEESMC64_OPTEED_RETURN_FIQ_DONE
+ */
+#define TEESMC_OPTEED_FUNCID_RETURN_FIQ_DONE		6
+#define TEESMC32_OPTEED_RETURN_FIQ_DONE \
+	TEESMC_CALL_VAL(TEESMC_32, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_FIQ_DONE)
+#define TEESMC64_OPTEED_RETURN_FIQ_DONE \
+	TEESMC_CALL_VAL(TEESMC_64, TEESMC_FAST_CALL, \
+			TEESMC_OWNER_TRUSTED_OS_OPTEED, \
+			TEESMC_OPTEED_FUNCID_RETURN_FIQ_DONE)
+
+#endif /*TEESMC_OPTEED_H*/
